<!DOCTYPE html>
<html>
<head>
	<link rel="stylesheet" href="../style.css">
	<meta http-equiv="content-type" content="text/html; charset=utf-8"/>
	<title>If AI Continues This Way, We are Doomed</title>
	<meta name="generator" content="LibreOffice 25.2.3.2 (Linux)"/>
	<meta name="created" content="00:00:00"/>
	<meta name="changed" content="00:00:00"/>
	<style type="text/css">
		@page { margin: 0.79in }
		p { margin-bottom: 0.1in }
	</style>
</head>
<body lang="en-US" dir="ltr"><p align="center" style="line-height: 100%; margin-top: 0.17in; margin-bottom: 0.08in; page-break-after: avoid">
<font face="Liberation Sans, sans-serif"><font size="6" style="font-size: 28pt"><b>If
AI Continues This Way, We are Doomed</b></font></font></p>
<p><br/>
<br/>

</p>
<p>	Often people say things like this about AI taking over, but right
now the problem is young people relying on AI. I know some people
would say “AI is just a tool, you just need to get used to it!”
but people are actually relying on it for more than just writing
stupid poems about random crap. 
</p>
<h1 align="center">People are Relying on AI</h1>
<p>	In <a href="https://youtu.be/ctcMA6chfDY">this</a> interview Sam
Altman tells us the statistics of how people are using OpenAI’s
ChatGPT. He says that Older people use it like an improved search
engine, which is basically how I use it, even though I’m still
pretty young. However, Altman also said most young people used it as
an operating system. Even worse, some even use it for life advice. I
have never done this and neither have any of my friends (at least to
my knowledge). He goes on to say that these people have given the AI
information on all of the people in their life so it can give them
better advice. This will only keep getting worse as reliance on AI
increases. I really hope these statistics aren’t completely true
and are just some stupid way to try and lead people to an AI based
workflow.</p>
<p>	The prospect of AI doing things for you seems very appealing,
especially to people who tend to be super lazy. This includes people
in high positions. Recently a judge reportedly <a href="https://arstechnica.com/tech-policy/2025/05/judge-initially-fooled-by-fake-ai-citations-nearly-put-them-in-a-ruling/">was
nearly persuaded by AI hallucinations</a> in a lawyer’s research.
This wouldn’t seem that bad, but LLMs are known to give wrong
information, since they merely query from a huge database of training
data. People, especially people in power, should not trust this
unreliable source of information.</p>
<p>	People already say some of the same things about all electronics.
People are constantly on their phones. Every free moment they check
social media or text a friend. I am guilty of this too. The real
problem I see is if people begin relying on this for everything,
especially with AI. If AI influences people’s every decision,
whoever controls AI, controls the world. People can influence
people’s views on everything. Similar to how all information was
censored and controlled by the government in the Soviet Union.
Everything had to conform to the ideals of the government. Similarly,
the AI companies such as OpenAI would have complete control over what
data is being fed to the user. My worst fear is that humans will just
be doing nothing but sitting around while the AI is constantly
feeding content into their brains.</p>
<h1 align="center">Vibe Coding</h1>
<p>	An <a href="https://thenewstack.io/a-practical-roadmap-for-vibe-coding-adoption/">article</a>
by Emilio Salvador from GitLab talks about how “Vibe Coding” is
the future. If you live under a rock and don’t know what vibe
coding is yet, it is basically just relying on AI to write all of
your code for you. This article explains how AI should be adopted
gradually, beginning with just using simple assistance, and
eventually use AI to automate almost all tasks involved in software
development. There was a similar situation with LSPs in their early
days. People believed they would decrease peoples programming skills,
the same things being said about AI completion. But look at how many
people have adopted LSPs and auto-complete now. It is basically an
industry standard at this point. The difference is, instead of just
helping people remember different functions and such, the AI writes
long segments of code by itself. 
</p>
<p>	AI companies seem to be all for this as most of the larger ones
including OpenAI and Anthropic have their own programming specific
models trained on mainly programming data. OpenAI also recently
bought Windsurf, a VsCode fork focusing on an AI based workflow. Even
Nvidia’s CEO, Jensen Huang told young people not to learn
programming, because AI will take over in the future. The problem
with this approach is that AI can’t innovate. It can find a way to
do something that’s been done before, but it can’t find a
creative solution to a problem. It bases it’s answers on a huge
database of previous methods and finds a solution based on that. LLMs
will never replace humans in innovation.</p>
<p>
</p>
<h1 align="center">Sentient AI</h1>
<p>	The prospect of AI in it’s current form being sentient is
absurd. As I mentioned before, it is currently just LLMs querying
huge databases. Even so, <a href="https://futurism.com/anthropic-ceo-suggests-ai-deserves-workers-rights">Anthropic
seems to think it deserves workers' rights</a>. He claims that if it
can do some of human’s jobs as well as humans it should be treated
like a human. I fundamentally disagree with this. A horse can pull a
cart better than a human, but that does not mean it has human
intelligence. Similarly, a machine can manufacture things faster than
humans doing it by hand, but does that make it human? AI is a tool
that that we use to accomplish tasks faster than we can ourselves.
For example, it can summarize an article in a few seconds, and decide
whether it is worth reading. Though I think what Anthropic is
suggesting here is extremely stupid, the fact they are actually
suggesting things like this is hilarious. 
</p>
<p>	It is possible that we will eventually get AI that doesn’t just
stand for Artificial Incompetence, but for now, people need to just
stop obsessing over it. Sure, it can be a useful tool, but I don’t
want it to become something everyone relies on in their daily lives.
I know some people said the same thing about the internet, but the
internet doesn’t do things for people, it just gets them the
information they need to do something. AI companies goals seem to be
that people barely do any work, except for outside physical jobs.
They are trying to replace a lot of tech jobs, like programming.
People need to resist this by reducing reliance on AI and not trading
their existing skills for prompting skills.</p>
<br>
<p style="text-align: right;">Lukas Zuercher</p
</body>
</html>
